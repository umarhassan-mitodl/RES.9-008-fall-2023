---
content_type: page
description: Seminar contents.
draft: false
title: Linear Network Theory and Sloppy Models
uid: 7139c8a4-6d32-46d5-a908-565bc0202de6
---
**Taught by:** *Mark Goldman, UC Davis (November 21, 2016)*

**Description:** This tutorial describes how to apply linear network theory to the analysis and interpretation of neural data. It introduces the concept of “sloppy models” that capture a common problem in model-fitting, in which individual model parameters are poorly constrained by available data (i.e. have “poorly/sloppily constrained parameter values”). Simple methods are illustrated for describing which combination of parameters most affect a particular model fit. This material is relevant to problems in neuroscience involving the interpretation of multidimensional data from recurrently connected systems.

**Slides:**

- [Linear Network Theory and Sloppy Models (PPT)](https://cbmm.mit.edu/sites/default/files/learning-hub/MITTutorialsTalk_LinearNe---ry_SloppyModels16_0.pptx) (Mark Goldman’s lecture slides)
- [Introduction to Linear Algebra (PPT)](https://cbmm.mit.edu/sites/default/files/learning-hub/LinearAlgebra_2016updatedFromwiki.ppt) (Mark Goldman and Emily Mackevicius slides)

**Additional Resources:**

- [Sloppy model problems](https://cbmm.mit.edu/sites/default/files/documents/SloppyModelProblems.docx)
- [Linear network theory problems](https://cbmm.mit.edu/sites/default/files/learning-hub/Linear_network_theory_problem.pdf)
- MATLAB code: [Integration for a recurrently connected network of two neurons](https://cbmm.mit.edu/sites/default/files/documents/Recurrent2CellNet_WoodsHole_Integration.m)
- MATLAB code: [Amplification for a recurrently connected network of two neurons](https://cbmm.mit.edu/sites/default/files/documents/Recurrent2CellNet_WoodsHole_Amplification.m)